{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../db.sqlite3')\n",
    "df = pd.read_sql_table('disasterdata', engine)\n",
    "# X should be the message column and Y should be all of the other columns. So Y is multivariable or something?\n",
    "X = np.ravel(df[[\"message\"]].values)\n",
    "column_names = list(df.iloc[:,4:100].columns)\n",
    "y = df.iloc[:, 4:100].values\n",
    "\n",
    "# actually, I'm thinking the above might be incorrect. I think I would have to create the \"def load_data()\" function\n",
    "# something like:\n",
    "# def load_data():\n",
    "#     df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
    "#     df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
    "#     X = df.text.values\n",
    "#     y = df.category.values\n",
    "#     return X, y\n",
    "\n",
    "# so basically I guess it's mainly the category confidence and exclude portions that I need to add?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['related',\n",
       "  'request',\n",
       "  'offer',\n",
       "  'aid_related',\n",
       "  'medical_help',\n",
       "  'medical_products',\n",
       "  'search_and_rescue',\n",
       "  'security',\n",
       "  'military',\n",
       "  'child_alone',\n",
       "  'water',\n",
       "  'food',\n",
       "  'shelter',\n",
       "  'clothing',\n",
       "  'money',\n",
       "  'missing_people',\n",
       "  'refugees',\n",
       "  'death',\n",
       "  'other_aid',\n",
       "  'infrastructure_related',\n",
       "  'transport',\n",
       "  'buildings',\n",
       "  'electricity',\n",
       "  'tools',\n",
       "  'hospitals',\n",
       "  'shops',\n",
       "  'aid_centers',\n",
       "  'other_infrastructure',\n",
       "  'weather_related',\n",
       "  'floods',\n",
       "  'storm',\n",
       "  'fire',\n",
       "  'earthquake',\n",
       "  'cold',\n",
       "  'other_weather',\n",
       "  'direct_report'],\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0]]),\n",
       " range(0, 36))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names, y, range(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-efda7f8559c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "range(column_names)\n",
    "\n",
    "#column_names is a list of strings\n",
    "#y_test is an array with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-652cffce6dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(classification_report(y_test[:,i], y_test[:,i]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "for i in column_names:\n",
    "    print(i)\n",
    "    c += 1\n",
    "    print(c)\n",
    "#     print(classification_report(y_test[:,i], y_test[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1526\n",
      "          1       1.00      1.00      1.00      4978\n",
      "          2       1.00      1.00      1.00        50\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "request\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5426\n",
      "          1       1.00      1.00      1.00      1128\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "offer\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6528\n",
      "          1       1.00      1.00      1.00        26\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "aid_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3813\n",
      "          1       1.00      1.00      1.00      2741\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "medical_help\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6047\n",
      "          1       1.00      1.00      1.00       507\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "medical_products\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6198\n",
      "          1       1.00      1.00      1.00       356\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "search_and_rescue\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6370\n",
      "          1       1.00      1.00      1.00       184\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "security\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6442\n",
      "          1       1.00      1.00      1.00       112\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "military\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6338\n",
      "          1       1.00      1.00      1.00       216\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "child_alone\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6554\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "water\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6106\n",
      "          1       1.00      1.00      1.00       448\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "food\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5847\n",
      "          1       1.00      1.00      1.00       707\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "shelter\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5944\n",
      "          1       1.00      1.00      1.00       610\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "clothing\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6439\n",
      "          1       1.00      1.00      1.00       115\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "money\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6406\n",
      "          1       1.00      1.00      1.00       148\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "missing_people\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6467\n",
      "          1       1.00      1.00      1.00        87\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "refugees\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6325\n",
      "          1       1.00      1.00      1.00       229\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "death\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6265\n",
      "          1       1.00      1.00      1.00       289\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "other_aid\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5683\n",
      "          1       1.00      1.00      1.00       871\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "infrastructure_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6143\n",
      "          1       1.00      1.00      1.00       411\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "transport\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6236\n",
      "          1       1.00      1.00      1.00       318\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "buildings\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6214\n",
      "          1       1.00      1.00      1.00       340\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "electricity\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6434\n",
      "          1       1.00      1.00      1.00       120\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "tools\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6522\n",
      "          1       1.00      1.00      1.00        32\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "hospitals\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6491\n",
      "          1       1.00      1.00      1.00        63\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "shops\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6527\n",
      "          1       1.00      1.00      1.00        27\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "aid_centers\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6474\n",
      "          1       1.00      1.00      1.00        80\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "other_infrastructure\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6277\n",
      "          1       1.00      1.00      1.00       277\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "weather_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      4740\n",
      "          1       1.00      1.00      1.00      1814\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "floods\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6004\n",
      "          1       1.00      1.00      1.00       550\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "storm\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5931\n",
      "          1       1.00      1.00      1.00       623\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "fire\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6476\n",
      "          1       1.00      1.00      1.00        78\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "earthquake\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5958\n",
      "          1       1.00      1.00      1.00       596\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "cold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6402\n",
      "          1       1.00      1.00      1.00       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "other_weather\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6234\n",
      "          1       1.00      1.00      1.00       320\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "direct_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5308\n",
      "          1       1.00      1.00      1.00      1246\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(column_names)):\n",
    "    print(column_names[i])\n",
    "    print(classification_report(y_test[:,i], y_test[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_url = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "# want to use the message column and take the necessary steps to process it: normalize, tokenize, stop word removal, \n",
    "# and stem and lemmatize. \n",
    "\n",
    "# look at this page for the flow of the maching learning pipeline: https://learn.udacity.com/nanodegrees/nd025/parts/cd0018/lessons/ls12134/concepts/08e7389d-f63b-4c73-9242-9cfe0b89ae21\n",
    "\n",
    "# I don't think there would be any URLs in the text, so we don't need the first bit of code?\n",
    "def tokenize_custom(text):\n",
    "    url_detect = re.findall(regex_url, text)\n",
    "    for url in url_detect:\n",
    "        text = text.replace(url, \"place_holder_url\")\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_words = []\n",
    "    for word in words:\n",
    "        clean_word = lemmatizer.lemmatize(word).lower().strip()\n",
    "        clean_words.append(clean_word)\n",
    "\n",
    "    return clean_words\n",
    "\n",
    "\n",
    "# X, y = load_data()\n",
    "# for message in X[:5]:\n",
    "#     tokens = tokenize(message)\n",
    "#     print(message)\n",
    "#     print(tokens, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so down here, I think I need to replace the RandomForestClassifier() with MultiOutputClassifier()\n",
    "# also, I don't think we call the pipeline fit or predict functions until steps 4 and 5 respectively? and then I recall\n",
    "# the predict function in step 7?\n",
    "# def main():\n",
    "#     X, y = load_data()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=tokenize_custom)),\n",
    "    ('tefreq_indocfreq', TfidfTransformer()),\n",
    "    ('classifier', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # display results\n",
    "#     display_results(y_test, y_pred)\n",
    "\n",
    "\n",
    "# main()\n",
    "\n",
    "# yea I don't think we need to use feature union for this project. because we are only using the message column as input\n",
    "# actually, might need to add to step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26216,), (26216, 36))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# train classifier\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19662, 36)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6554, 36)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y and y_test are dataframes\n",
    "# y_pred is an array.\n",
    "\n",
    "# so the solution should be to make everything an array from the beginning. \n",
    "# but before doing that, create some new object storing the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 36)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.35      0.46      1548\n",
      "          1       0.82      0.94      0.87      4955\n",
      "          2       0.63      0.24      0.34        51\n",
      "\n",
      "avg / total       0.78      0.80      0.77      6554\n",
      "\n",
      "request\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93      5404\n",
      "          1       0.80      0.39      0.53      1150\n",
      "\n",
      "avg / total       0.87      0.88      0.86      6554\n",
      "\n",
      "offer\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6517\n",
      "          1       0.00      0.00      0.00        37\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6554\n",
      "\n",
      "aid_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.88      0.79      3824\n",
      "          1       0.75      0.50      0.60      2730\n",
      "\n",
      "avg / total       0.73      0.73      0.71      6554\n",
      "\n",
      "medical_help\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96      6022\n",
      "          1       0.69      0.09      0.16       532\n",
      "\n",
      "avg / total       0.91      0.92      0.89      6554\n",
      "\n",
      "medical_products\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6208\n",
      "          1       0.77      0.08      0.14       346\n",
      "\n",
      "avg / total       0.94      0.95      0.93      6554\n",
      "\n",
      "search_and_rescue\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6350\n",
      "          1       0.75      0.01      0.03       204\n",
      "\n",
      "avg / total       0.96      0.97      0.95      6554\n",
      "\n",
      "security\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6429\n",
      "          1       0.33      0.01      0.02       125\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6554\n",
      "\n",
      "military\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6336\n",
      "          1       0.67      0.06      0.12       218\n",
      "\n",
      "avg / total       0.96      0.97      0.95      6554\n",
      "\n",
      "child_alone\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6554\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "water\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6139\n",
      "          1       0.86      0.23      0.36       415\n",
      "\n",
      "avg / total       0.94      0.95      0.93      6554\n",
      "\n",
      "food\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      5815\n",
      "          1       0.84      0.37      0.51       739\n",
      "\n",
      "avg / total       0.92      0.92      0.91      6554\n",
      "\n",
      "shelter\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96      5990\n",
      "          1       0.78      0.16      0.26       564\n",
      "\n",
      "avg / total       0.91      0.92      0.90      6554\n",
      "\n",
      "clothing\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6434\n",
      "          1       0.85      0.14      0.24       120\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6554\n",
      "\n",
      "money\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6411\n",
      "          1       0.50      0.06      0.11       143\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6554\n",
      "\n",
      "missing_people\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6470\n",
      "          1       0.50      0.01      0.02        84\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6554\n",
      "\n",
      "refugees\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6322\n",
      "          1       0.53      0.04      0.07       232\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6554\n",
      "\n",
      "death\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6232\n",
      "          1       0.84      0.15      0.26       322\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6554\n",
      "\n",
      "other_aid\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93      5686\n",
      "          1       0.49      0.03      0.06       868\n",
      "\n",
      "avg / total       0.82      0.87      0.81      6554\n",
      "\n",
      "infrastructure_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6143\n",
      "          1       0.17      0.00      0.00       411\n",
      "\n",
      "avg / total       0.89      0.94      0.91      6554\n",
      "\n",
      "transport\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6241\n",
      "          1       0.68      0.10      0.18       313\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6554\n",
      "\n",
      "buildings\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6215\n",
      "          1       0.68      0.06      0.11       339\n",
      "\n",
      "avg / total       0.94      0.95      0.93      6554\n",
      "\n",
      "electricity\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6399\n",
      "          1       1.00      0.03      0.05       155\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6554\n",
      "\n",
      "tools\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6512\n",
      "          1       0.00      0.00      0.00        42\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6554\n",
      "\n",
      "hospitals\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6486\n",
      "          1       0.00      0.00      0.00        68\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6554\n",
      "\n",
      "shops\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6520\n",
      "          1       0.00      0.00      0.00        34\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6554\n",
      "\n",
      "aid_centers\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6474\n",
      "          1       0.00      0.00      0.00        80\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6554\n",
      "\n",
      "other_infrastructure\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6273\n",
      "          1       0.40      0.01      0.01       281\n",
      "\n",
      "avg / total       0.93      0.96      0.94      6554\n",
      "\n",
      "weather_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.89      4704\n",
      "          1       0.85      0.49      0.62      1850\n",
      "\n",
      "avg / total       0.83      0.83      0.81      6554\n",
      "\n",
      "floods\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      5995\n",
      "          1       0.85      0.27      0.41       559\n",
      "\n",
      "avg / total       0.93      0.93      0.92      6554\n",
      "\n",
      "storm\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      5940\n",
      "          1       0.77      0.34      0.47       614\n",
      "\n",
      "avg / total       0.92      0.93      0.92      6554\n",
      "\n",
      "fire\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6488\n",
      "          1       1.00      0.03      0.06        66\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6554\n",
      "\n",
      "earthquake\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      5962\n",
      "          1       0.92      0.55      0.69       592\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6554\n",
      "\n",
      "cold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6421\n",
      "          1       0.71      0.08      0.14       133\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6554\n",
      "\n",
      "other_weather\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6150\n",
      "          1       0.73      0.02      0.04       404\n",
      "\n",
      "avg / total       0.93      0.94      0.91      6554\n",
      "\n",
      "direct_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91      5305\n",
      "          1       0.78      0.31      0.44      1249\n",
      "\n",
      "avg / total       0.84      0.85      0.82      6554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in range(36):\n",
    "    print(column_names[i])\n",
    "    print(classification_report(y_test[:,i], y_pred[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vectorizer',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize_custom at 0x7f1fe7473488>,\n",
       "           vocabulary=None)),\n",
       "  ('tefreq_indocfreq',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('classifier',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "               max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "               oob_score=False, random_state=None, verbose=0,\n",
       "               warm_start=False),\n",
       "              n_jobs=1))],\n",
       " 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize_custom at 0x7f1fe7473488>,\n",
       "         vocabulary=None),\n",
       " 'tefreq_indocfreq': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'classifier': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       "            n_jobs=1),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': <function __main__.tokenize_custom(text)>,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'tefreq_indocfreq__norm': 'l2',\n",
       " 'tefreq_indocfreq__smooth_idf': True,\n",
       " 'tefreq_indocfreq__sublinear_tf': False,\n",
       " 'tefreq_indocfreq__use_idf': True,\n",
       " 'classifier__estimator__bootstrap': True,\n",
       " 'classifier__estimator__class_weight': None,\n",
       " 'classifier__estimator__criterion': 'gini',\n",
       " 'classifier__estimator__max_depth': None,\n",
       " 'classifier__estimator__max_features': 'auto',\n",
       " 'classifier__estimator__max_leaf_nodes': None,\n",
       " 'classifier__estimator__min_impurity_decrease': 0.0,\n",
       " 'classifier__estimator__min_impurity_split': None,\n",
       " 'classifier__estimator__min_samples_leaf': 1,\n",
       " 'classifier__estimator__min_samples_split': 2,\n",
       " 'classifier__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'classifier__estimator__n_estimators': 10,\n",
       " 'classifier__estimator__n_jobs': 1,\n",
       " 'classifier__estimator__oob_score': False,\n",
       " 'classifier__estimator__random_state': None,\n",
       " 'classifier__estimator__verbose': 0,\n",
       " 'classifier__estimator__warm_start': False,\n",
       " 'classifier__estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'classifier__n_jobs': 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'classifier__estimator__n_estimators': [5, 10],\n",
    "    'classifier__estimator__min_samples_split': [2, 3]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=3, n_jobs=8, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=10 \n",
      "[CV] classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=10 \n",
      "[CV] classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=10 \n",
      "[CV] classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=20 \n",
      "[CV] classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=20 \n",
      "[CV] classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=20 \n",
      "[CV] classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=30 \n",
      "[CV] classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=30 \n",
      "[CV]  classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=10, score=0.21635642355813245, total= 6.7min\n",
      "[CV] classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=30 \n",
      "[CV]  classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=10, score=0.2168141592920354, total= 6.7min\n",
      "[CV] classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=10 \n",
      "[CV]  classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=10, score=0.2162038449801648, total= 6.8min\n",
      "[CV] classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=10 \n",
      "[CV]  classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=20, score=0.21849252364967958, total=11.9min\n",
      "[CV] classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=10 \n",
      "[CV]  classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=20, score=0.22490082392432104, total=12.0min\n",
      "[CV] classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=20, score=0.23390296002441258, total=12.0min\n",
      "[CV] classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=10, score=0.21010070186145866, total= 6.3min\n",
      "[CV] classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=10, score=0.20720170888007325, total= 6.2min\n",
      "[CV] classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=30 \n",
      "[CV]  classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=30, score=0.2239853524565151, total=17.4min\n",
      "[CV]  classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=30, score=0.23146170277693012, total=17.5min\n",
      "[CV] classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=30 \n",
      "[CV] classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  18 | elapsed: 19.7min remaining: 15.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=10, score=0.2050656087885261, total= 6.2min\n",
      "[CV]  classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=20, score=0.21895025938358254, total=10.5min\n",
      "[CV]  classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=20, score=0.22978333841928594, total=10.6min\n",
      "[CV]  classifier__estimator__min_samples_split=2, classifier__estimator__n_estimators=30, score=0.22657918828196522, total=16.7min\n",
      "[CV]  classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=20, score=0.21101617332926456, total=10.2min\n",
      "[CV]  classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=30, score=0.24092157461092462, total=12.3min\n",
      "[CV]  classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=30, score=0.22703692401586817, total= 9.5min\n",
      "[CV]  classifier__estimator__min_samples_split=3, classifier__estimator__n_estimators=30, score=0.21574610924626184, total= 9.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  18 out of  18 | elapsed: 29.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'classifier__estimator__n_estimators': [10, 20, 30], 'classifier__estimator__min_samples_split': [2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-26224c4c6912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_best = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b0d1b25fe220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(36):\n",
    "    print(column_names[i])\n",
    "    print(classification_report(y_test[:,i], y_pred_best[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually, we would add feature union to step 8 here potentially\n",
    "# this would also be where we add custom transformers I'm assuming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cv, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
